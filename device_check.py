"""
å¿«é€Ÿè®¾å¤‡æ£€æŸ¥è„šæœ¬
åœ¨æ­£å¼è®­ç»ƒå‰éªŒè¯æ‰€æœ‰ç»„ä»¶çš„è®¾å¤‡é…ç½®
"""

import torch
import argparse
import os
import sys
from torch.utils.data import DataLoader

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from sub_model.conflict_model import UAVConflictModel
from trainer.losses import OccupancyLoss, MotionLoss, MultiTaskLoss
from trainer.metrics import Metrics
from trainer.risk_evaluator import RiskEvaluator
from image_dataset import UAVImageDataset, UAVSimpleImageDataset
from validation_visualizer import ValidationVisualizer


class DeviceChecker:
    """è®¾å¤‡ä¸€è‡´æ€§æ£€æŸ¥å™¨"""

    def __init__(self, config):
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() and config.device == 'cuda' else 'cpu')
        self.errors = []
        self.warnings = []

        print("=" * 70)
        print("ğŸ” UAV æ¨¡å‹è®¾å¤‡å¿«é€Ÿæ£€æŸ¥")
        print("=" * 70)
        print(f"ç›®æ ‡è®¾å¤‡: {self.device}")
        if torch.cuda.is_available():
            print(f"GPU: {torch.cuda.get_device_name(0)}")
            print(f"æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
        print("=" * 70 + "\n")

    def log_error(self, module, message):
        """è®°å½•é”™è¯¯"""
        error_msg = f"âŒ [{module}] {message}"
        self.errors.append(error_msg)
        print(error_msg)

    def log_warning(self, module, message):
        """è®°å½•è­¦å‘Š"""
        warning_msg = f"âš ï¸  [{module}] {message}"
        self.warnings.append(warning_msg)
        print(warning_msg)

    def log_success(self, module, message):
        """è®°å½•æˆåŠŸ"""
        print(f"âœ… [{module}] {message}")

    def check_dataset(self):
        """æ£€æŸ¥æ•°æ®é›†åŠ è½½å™¨"""
        print("\n" + "â”€" * 70)
        print("1ï¸âƒ£  æ£€æŸ¥æ•°æ®é›†...")
        print("â”€" * 70)

        try:
            use_occ = self.config.mode in ['occupancy', 'multitask']
            use_motion = self.config.mode in ['motion', 'multitask']

            if self.config.dataset_type == 'sequence':
                dataset = UAVImageDataset(
                    root_dir=self.config.data_dir,
                    history_frames=self.config.history_frames,
                    use_occ=use_occ,
                    use_motion=use_motion,
                    img_size=tuple(self.config.img_size)
                )
            else:
                dataset = UAVSimpleImageDataset(
                    root_dir=self.config.data_dir,
                    img_size=tuple(self.config.img_size),
                    use_occ=use_occ,
                    use_motion=use_motion
                )

            if len(dataset) == 0:
                self.log_error("Dataset", "æ•°æ®é›†ä¸ºç©º")
                return False

            self.log_success("Dataset", f"æ‰¾åˆ° {len(dataset)} ä¸ªæ ·æœ¬")

            # åˆ›å»ºå°å‹ DataLoader (åªå– 2 ä¸ªæ ·æœ¬)
            mini_loader = DataLoader(
                dataset,
                batch_size=1,
                shuffle=False,
                num_workers=0,
                pin_memory=torch.cuda.is_available()
            )

            # æ£€æŸ¥ç¬¬ä¸€ä¸ª batch
            history, targets = next(iter(mini_loader))

            self.log_success("Dataset", f"History shape: {history.shape}")
            for key, value in targets.items():
                if isinstance(value, torch.Tensor):
                    self.log_success("Dataset", f"Target '{key}' shape: {value.shape}")

            # æµ‹è¯•è®¾å¤‡è½¬ç§»
            history_gpu = history.to(self.device, non_blocking=True)
            if history_gpu.device.type != self.device.type:
                self.log_error("Dataset", f"æ•°æ®æ— æ³•ç§»åŠ¨åˆ° {self.device}")
                return False

            self.log_success("Dataset", f"æ•°æ®æˆåŠŸç§»åŠ¨åˆ° {self.device}")

            # ä¿å­˜æ ·æœ¬ç”¨äºåç»­æµ‹è¯•
            self.test_history = history_gpu
            self.test_targets = {k: v.to(self.device, non_blocking=True) if isinstance(v, torch.Tensor) else v
                                for k, v in targets.items()}

            return True

        except Exception as e:
            self.log_error("Dataset", f"å¼‚å¸¸: {str(e)}")
            import traceback
            traceback.print_exc()
            return False

    def check_model(self):
        """æ£€æŸ¥æ¨¡å‹"""
        print("\n" + "â”€" * 70)
        print("2ï¸âƒ£  æ£€æŸ¥æ¨¡å‹...")
        print("â”€" * 70)

        try:
            self.model = UAVConflictModel(
                mode=self.config.mode,
                hidden_dim=self.config.hidden_dim,
                modes=self.config.num_modes,
                encoder_backbone=self.config.backbone,
                future_steps=self.config.future_steps
            ).to(self.device)

            total_params = sum(p.numel() for p in self.model.parameters())
            self.log_success("Model", f"æ¨¡å‹åˆ›å»ºæˆåŠŸï¼Œå‚æ•°é‡: {total_params / 1e6:.2f}M")

            # æ£€æŸ¥æ‰€æœ‰å‚æ•°æ˜¯å¦åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
            devices = {p.device for p in self.model.parameters()}
            if len(devices) > 1:
                self.log_error("Model", f"æ¨¡å‹å‚æ•°åœ¨å¤šä¸ªè®¾å¤‡ä¸Š: {devices}")
                return False

            model_device = next(self.model.parameters()).device
            if model_device.type != self.device.type:
                self.log_error("Model", f"æ¨¡å‹åœ¨ {model_device}ï¼ŒæœŸæœ› {self.device}")
                return False

            self.log_success("Model", f"æ‰€æœ‰å‚æ•°éƒ½åœ¨ {self.device} ä¸Š")

            # âœ… ä¿®å¤ï¼šä½¿ç”¨è®­ç»ƒæ¨¡å¼è¿›è¡Œå‰å‘ä¼ æ’­ï¼ˆä¿ç•™æ¢¯åº¦ï¼‰
            self.model.train()
            outputs = self.model(self.test_history, return_confidence=True)

            # æ£€æŸ¥è¾“å‡ºè®¾å¤‡
            if self.config.mode == 'multitask':
                occ_pred, occ_conf = outputs['occ']
                if occ_pred.device.type != self.device.type:
                    self.log_error("Model", f"Occupancyè¾“å‡ºåœ¨ {occ_pred.device}")
                    return False
                self.log_success("Model", f"Occupancyè¾“å‡º: {occ_pred.shape}, device: {occ_pred.device}")

                motion_pred, motion_conf = outputs['motion']
                if motion_pred.device.type != self.device.type:
                    self.log_error("Model", f"Motionè¾“å‡ºåœ¨ {motion_pred.device}")
                    return False
                self.log_success("Model", f"Motionè¾“å‡º: {motion_pred.shape}, device: {motion_pred.device}")

            elif self.config.mode == 'occupancy':
                pred, conf = outputs
                if pred.device.type != self.device.type:
                    self.log_error("Model", f"è¾“å‡ºåœ¨ {pred.device}")
                    return False
                self.log_success("Model", f"Occupancyè¾“å‡º: {pred.shape}, device: {pred.device}")

            else:  # motion
                pred, conf = outputs
                if pred.device.type != self.device.type:
                    self.log_error("Model", f"è¾“å‡ºåœ¨ {pred.device}")
                    return False
                self.log_success("Model", f"Motionè¾“å‡º: {pred.shape}, device: {pred.device}")

            self.test_outputs = outputs
            return True

        except Exception as e:
            self.log_error("Model", f"å¼‚å¸¸: {str(e)}")
            import traceback
            traceback.print_exc()
            return False

    def check_loss(self):
        """æ£€æŸ¥æŸå¤±å‡½æ•°"""
        print("\n" + "â”€" * 70)
        print("3ï¸âƒ£  æ£€æŸ¥æŸå¤±å‡½æ•°...")
        print("â”€" * 70)

        try:
            if self.config.mode == 'multitask':
                criterion = MultiTaskLoss(
                    risk_weight=self.config.risk_weight,
                    risk_w_var=self.config.risk_w_var,
                    risk_w_ent=self.config.risk_w_ent,
                    risk_w_temp=self.config.risk_w_temp,
                    occ_weight=self.config.occ_weight,
                    motion_weight=self.config.motion_weight
                ).to(self.device)
            elif self.config.mode == 'occupancy':
                criterion = OccupancyLoss(
                    self.config.risk_weight,
                    self.config.risk_w_var,
                    self.config.risk_w_ent,
                    self.config.risk_w_temp
                ).to(self.device)
            else:
                criterion = MotionLoss().to(self.device)

            self.log_success("Loss", f"æŸå¤±å‡½æ•°åˆ›å»ºæˆåŠŸ ({self.config.mode} mode)")

            # æµ‹è¯•æŸå¤±è®¡ç®—
            if self.config.mode == 'multitask':
                losses = criterion(self.test_outputs, self.test_targets)
                loss = losses['total']
            elif self.config.mode == 'occupancy':
                pred, conf = self.test_outputs
                loss, details = criterion(pred, self.test_targets['occ'], conf)
            else:
                pred, conf = self.test_outputs
                loss, details = criterion(pred, self.test_targets['motion'], conf)

            if loss.device.type != self.device.type:
                self.log_error("Loss", f"æŸå¤±åœ¨ {loss.device}ï¼ŒæœŸæœ› {self.device}")
                return False

            self.log_success("Loss", f"æŸå¤±è®¡ç®—æˆåŠŸ: {loss.item():.4f}, device: {loss.device}")

            # æµ‹è¯•åå‘ä¼ æ’­
            self.model.train()
            self.model.zero_grad()
            loss.backward()

            # æ£€æŸ¥æ¢¯åº¦è®¾å¤‡
            grad_devices = {p.grad.device for p in self.model.parameters() if p.grad is not None}
            if len(grad_devices) > 1:
                self.log_error("Loss", f"æ¢¯åº¦åœ¨å¤šä¸ªè®¾å¤‡ä¸Š: {grad_devices}")
                return False

            self.log_success("Loss", "åå‘ä¼ æ’­æˆåŠŸï¼Œæ¢¯åº¦è®¡ç®—æ­£ç¡®")

            return True

        except Exception as e:
            self.log_error("Loss", f"å¼‚å¸¸: {str(e)}")
            import traceback
            traceback.print_exc()
            return False

    def check_metrics(self):
        """æ£€æŸ¥è¯„ä¼°æŒ‡æ ‡"""
        print("\n" + "â”€" * 70)
        print("4ï¸âƒ£  æ£€æŸ¥è¯„ä¼°æŒ‡æ ‡...")
        print("â”€" * 70)

        try:
            metrics = Metrics(
                self.config.risk_w_var,
                self.config.risk_w_ent,
                self.config.risk_w_temp
            )

            self.log_success("Metrics", "æŒ‡æ ‡è®¡ç®—å™¨åˆ›å»ºæˆåŠŸ")

            # æµ‹è¯•æŒ‡æ ‡è®¡ç®—
            if self.config.mode in ['occupancy', 'multitask']:
                if self.config.mode == 'multitask':
                    pred, conf = self.test_outputs['occ']
                else:
                    pred, conf = self.test_outputs

                result = metrics.compute_occ_metrics(pred, self.test_targets['occ'])

                self.log_success("Metrics", f"IoU: {result['iou']:.4f}")
                self.log_success("Metrics", f"Precision: {result['precision']:.4f}")
                self.log_success("Metrics", f"Recall: {result['recall']:.4f}")

                # æ£€æŸ¥è¿”å›å€¼æ˜¯å¦ä¸º Python æ ‡é‡
                if not isinstance(result['iou'], float):
                    self.log_warning("Metrics", "æŒ‡æ ‡è¿”å›å€¼ä¸æ˜¯ Python float")

            return True

        except Exception as e:
            self.log_error("Metrics", f"å¼‚å¸¸: {str(e)}")
            import traceback
            traceback.print_exc()
            return False

    def check_risk_evaluator(self):
        """æ£€æŸ¥é£é™©è¯„ä¼°å™¨"""
        print("\n" + "â”€" * 70)
        print("5ï¸âƒ£  æ£€æŸ¥é£é™©è¯„ä¼°å™¨...")
        print("â”€" * 70)

        try:
            risk_evaluator = RiskEvaluator(
                self.config.risk_w_var,
                self.config.risk_w_ent,
                self.config.risk_w_temp
            )

            self.log_success("RiskEvaluator", "é£é™©è¯„ä¼°å™¨åˆ›å»ºæˆåŠŸ")

            # æµ‹è¯•é£é™©è®¡ç®—
            if self.config.mode in ['occupancy', 'multitask']:
                if self.config.mode == 'multitask':
                    pred, conf = self.test_outputs['occ']
                else:
                    pred, conf = self.test_outputs

                # âœ… ä¿®å¤ï¼šç¡®ä¿ pred éœ€è¦æ¢¯åº¦
                # ä½¿ç”¨ sigmoid åçš„ç»“æœï¼Œå¹¶ç¡®ä¿éœ€è¦æ¢¯åº¦
                pred_detached = pred.detach()
                occ_prob = torch.sigmoid(pred_detached).requires_grad_(True)

                # æµ‹è¯•è®­ç»ƒæ¨¡å¼ (éœ€è¦æ¢¯åº¦)
                risks_train = risk_evaluator.compute_all_risks(occ_prob, differentiable=True)

                if risks_train['combined'].device.type != self.device.type:
                    self.log_error("RiskEvaluator", f"è®­ç»ƒæ¨¡å¼é£é™©åœ¨ {risks_train['combined'].device}")
                    return False

                self.log_success("RiskEvaluator", f"è®­ç»ƒæ¨¡å¼é£é™©: {risks_train['combined'].mean().item():.6f}")

                # æµ‹è¯•æ¢¯åº¦
                risk_loss = risks_train['combined'].mean()
                risk_loss.backward()

                if occ_prob.grad is None:
                    self.log_error("RiskEvaluator", "è®­ç»ƒæ¨¡å¼æœªè®¡ç®—æ¢¯åº¦")
                    return False

                self.log_success("RiskEvaluator", "è®­ç»ƒæ¨¡å¼æ¢¯åº¦è®¡ç®—æ­£ç¡®")

                # æµ‹è¯•è¯„ä¼°æ¨¡å¼ (ä¸éœ€è¦æ¢¯åº¦)
                with torch.no_grad():
                    risks_eval = risk_evaluator.compute_all_risks(torch.sigmoid(pred), differentiable=False)

                if risks_eval['combined'].requires_grad:
                    self.log_warning("RiskEvaluator", "è¯„ä¼°æ¨¡å¼ä¸åº”è¯¥æœ‰æ¢¯åº¦")

                self.log_success("RiskEvaluator", "è¯„ä¼°æ¨¡å¼æ­£å¸¸")

                # æµ‹è¯•æ‘˜è¦
                summary = risk_evaluator.get_risk_summary(torch.sigmoid(pred))

                if not all(isinstance(v, float) for v in summary.values()):
                    self.log_warning("RiskEvaluator", "æ‘˜è¦è¿”å›å€¼ä¸æ˜¯ Python float")
                else:
                    self.log_success("RiskEvaluator", "æ‘˜è¦è®¡ç®—æ­£ç¡®")

            return True

        except Exception as e:
            self.log_error("RiskEvaluator", f"å¼‚å¸¸: {str(e)}")
            import traceback
            traceback.print_exc()
            return False

    def check_visualizer(self):
        """æ£€æŸ¥å¯è§†åŒ–å™¨"""
        print("\n" + "â”€" * 70)
        print("6ï¸âƒ£  æ£€æŸ¥å¯è§†åŒ–å™¨...")
        print("â”€" * 70)

        try:
            import tempfile
            temp_dir = tempfile.mkdtemp()

            visualizer = ValidationVisualizer(temp_dir, mode=self.config.mode)

            self.log_success("Visualizer", "å¯è§†åŒ–å™¨åˆ›å»ºæˆåŠŸ")

            # æµ‹è¯•å¯è§†åŒ– (æ•°æ®éœ€è¦åœ¨ CPU ä¸Š)
            history_cpu = self.test_history.cpu()
            targets_cpu = {k: v.cpu() if isinstance(v, torch.Tensor) else v
                          for k, v in self.test_targets.items()}

            if self.config.mode == 'multitask':
                outputs_cpu = {
                    'occ': (self.test_outputs['occ'][0].cpu(), self.test_outputs['occ'][1].cpu()),
                    'motion': (self.test_outputs['motion'][0].cpu(), self.test_outputs['motion'][1].cpu())
                }
            elif self.config.mode == 'occupancy':
                outputs_cpu = (self.test_outputs[0].cpu(), self.test_outputs[1].cpu())
            else:
                outputs_cpu = (self.test_outputs[0].cpu(), self.test_outputs[1].cpu())

            paths = visualizer.visualize_batch(
                history_cpu, outputs_cpu, targets_cpu,
                epoch=0, batch_idx=0, max_samples=1
            )

            if paths:
                self.log_success("Visualizer", f"å¯è§†åŒ–æˆåŠŸ: {len(paths)} ä¸ªæ–‡ä»¶")
            else:
                self.log_warning("Visualizer", "æœªç”Ÿæˆå¯è§†åŒ–æ–‡ä»¶")

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            import shutil
            shutil.rmtree(temp_dir)

            return True

        except Exception as e:
            self.log_error("Visualizer", f"å¼‚å¸¸: {str(e)}")
            import traceback
            traceback.print_exc()
            return False

    def check_memory(self):
        """æ£€æŸ¥æ˜¾å­˜ä½¿ç”¨"""
        print("\n" + "â”€" * 70)
        print("7ï¸âƒ£  æ£€æŸ¥æ˜¾å­˜ä½¿ç”¨...")
        print("â”€" * 70)

        if not torch.cuda.is_available():
            self.log_warning("Memory", "CPU æ¨¡å¼ï¼Œè·³è¿‡æ˜¾å­˜æ£€æŸ¥")
            return True

        try:
            torch.cuda.empty_cache()
            torch.cuda.reset_peak_memory_stats()

            # æ¨¡æ‹Ÿä¸€ä¸ªå®Œæ•´çš„è®­ç»ƒæ­¥éª¤
            self.model.train()
            self.model.zero_grad()

            # å‰å‘ä¼ æ’­
            outputs = self.model(self.test_history, return_confidence=True)

            if self.config.mode == 'multitask':
                criterion = MultiTaskLoss().to(self.device)
                losses = criterion(outputs, self.test_targets)
                loss = losses['total']
            elif self.config.mode == 'occupancy':
                criterion = OccupancyLoss().to(self.device)
                pred, conf = outputs
                loss, _ = criterion(pred, self.test_targets['occ'], conf)
            else:
                criterion = MotionLoss().to(self.device)
                pred, conf = outputs
                loss, _ = criterion(pred, self.test_targets['motion'], conf)

            # åå‘ä¼ æ’­
            loss.backward()

            # è·å–æ˜¾å­˜ä½¿ç”¨
            allocated = torch.cuda.memory_allocated() / 1e9
            reserved = torch.cuda.memory_reserved() / 1e9
            peak = torch.cuda.max_memory_allocated() / 1e9
            total = torch.cuda.get_device_properties(0).total_memory / 1e9

            self.log_success("Memory", f"å½“å‰ä½¿ç”¨: {allocated:.2f} GB")
            self.log_success("Memory", f"å³°å€¼ä½¿ç”¨: {peak:.2f} GB")
            self.log_success("Memory", f"æ€»æ˜¾å­˜: {total:.2f} GB")
            self.log_success("Memory", f"ä½¿ç”¨ç‡: {peak / total * 100:.1f}%")

            if peak / total > 0.9:
                self.log_warning("Memory", "æ˜¾å­˜ä½¿ç”¨ç‡è¶…è¿‡ 90%ï¼Œå»ºè®®å‡å° batch_size")

            torch.cuda.empty_cache()
            return True

        except Exception as e:
            self.log_error("Memory", f"å¼‚å¸¸: {str(e)}")
            import traceback
            traceback.print_exc()
            return False

    def run_all_checks(self):
        """è¿è¡Œæ‰€æœ‰æ£€æŸ¥"""
        checks = [
            ("æ•°æ®é›†", self.check_dataset),
            ("æ¨¡å‹", self.check_model),
            ("æŸå¤±å‡½æ•°", self.check_loss),
            ("è¯„ä¼°æŒ‡æ ‡", self.check_metrics),
            ("é£é™©è¯„ä¼°å™¨", self.check_risk_evaluator),
            ("å¯è§†åŒ–å™¨", self.check_visualizer),
            ("æ˜¾å­˜", self.check_memory),
        ]

        results = {}
        for name, check_func in checks:
            try:
                results[name] = check_func()
            except KeyboardInterrupt:
                print("\n\næ£€æŸ¥è¢«ç”¨æˆ·ä¸­æ–­")
                return False
            except Exception as e:
                print(f"\nâŒ æ£€æŸ¥ '{name}' æ—¶å‘ç”Ÿæœªæ•è·å¼‚å¸¸: {e}")
                import traceback
                traceback.print_exc()
                results[name] = False

        # æ‰“å°æ€»ç»“
        print("\n" + "=" * 70)
        print("ğŸ“Š æ£€æŸ¥ç»“æœæ±‡æ€»")
        print("=" * 70)

        for name, passed in results.items():
            status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥"
            print(f"{status} - {name}")

        print("=" * 70)

        if self.errors:
            print(f"\nâŒ å‘ç° {len(self.errors)} ä¸ªé”™è¯¯:")
            for error in self.errors:
                print(f"  {error}")

        if self.warnings:
            print(f"\nâš ï¸  å‘ç° {len(self.warnings)} ä¸ªè­¦å‘Š:")
            for warning in self.warnings:
                print(f"  {warning}")

        all_passed = all(results.values())

        print("\n" + "=" * 70)
        if all_passed:
            print("ğŸ‰ æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼å¯ä»¥å¼€å§‹è®­ç»ƒã€‚")
        else:
            print("âš ï¸  éƒ¨åˆ†æ£€æŸ¥å¤±è´¥ï¼è¯·ä¿®å¤åå†è®­ç»ƒã€‚")
        print("=" * 70 + "\n")

        return all_passed


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    p = argparse.ArgumentParser(description='å¿«é€Ÿè®¾å¤‡æ£€æŸ¥')

    # æ•°æ®ç›¸å…³
    p.add_argument('--data_dir', default=r'D:\model_12.22_fixed\images',
                   help='æ•°æ®é›†æ ¹ç›®å½•')
    p.add_argument('--dataset_type', default='sequence', choices=['sequence', 'simple'],
                   help='æ•°æ®é›†ç±»å‹')
    p.add_argument('--history_frames', type=int, default=9,
                   help='å†å²å¸§æ•°')
    p.add_argument('--img_size', type=int, nargs=2, default=[640, 640],
                   help='å›¾åƒå°ºå¯¸')

    # æ¨¡å‹ç›¸å…³
    p.add_argument('--mode', default='occupancy', choices=['multitask', 'occupancy', 'motion'],
                   help='è®­ç»ƒæ¨¡å¼')
    p.add_argument('--backbone', default='resnet50',
                   help='ç¼–ç å™¨backbone')
    p.add_argument('--hidden_dim', type=int, default=128,
                   help='éšè—å±‚ç»´åº¦')
    p.add_argument('--num_modes', type=int, default=5,
                   help='æ¨¡æ€æ•°é‡')
    p.add_argument('--future_steps', type=int, default=1,
                   help='é¢„æµ‹æœªæ¥æ­¥æ•°')

    # Riskç›¸å…³
    p.add_argument('--risk_weight', type=float, default=0.01)
    p.add_argument('--risk_w_var', type=float, default=1.0)
    p.add_argument('--risk_w_ent', type=float, default=0.5)
    p.add_argument('--risk_w_temp', type=float, default=0.3)

    # MultiTaskæƒé‡
    p.add_argument('--occ_weight', type=float, default=1.0)
    p.add_argument('--motion_weight', type=float, default=1.0)

    # å…¶ä»–
    p.add_argument('--device', default='cuda',
                   help='è®­ç»ƒè®¾å¤‡')

    return p.parse_args()


if __name__ == "__main__":
    args = parse_args()

    print("\n" + "=" * 70)
    print("ğŸš€ å¼€å§‹å¿«é€Ÿè®¾å¤‡æ£€æŸ¥")
    print("=" * 70)
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
    print("=" * 70)

    checker = DeviceChecker(args)
    success = checker.run_all_checks()

    sys.exit(0 if success else 1)